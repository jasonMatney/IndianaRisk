{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "\n",
    "# h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) Client VM (build 25.241-b07, mixed mode)\n",
      "  Starting server from C:\\Users\\jmatney\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\jmatney\\AppData\\Local\\Temp\\tmpe9n9hgab\n",
      "  JVM stdout: C:\\Users\\jmatney\\AppData\\Local\\Temp\\tmpe9n9hgab\\h2o_jmatney_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\jmatney\\AppData\\Local\\Temp\\tmpe9n9hgab\\h2o_jmatney_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>03 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.30.0.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 7 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_jmatney_e7fxn2</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>247.5 Mb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.7.4 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------------\n",
       "H2O_cluster_uptime:         03 secs\n",
       "H2O_cluster_timezone:       America/New_York\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.30.0.3\n",
       "H2O_cluster_version_age:    1 month and 7 days\n",
       "H2O_cluster_name:           H2O_from_python_jmatney_e7fxn2\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    247.5 Mb\n",
       "H2O_cluster_total_cores:    0\n",
       "H2O_cluster_allowed_cores:  0\n",
       "H2O_cluster_status:         accepting new members, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.7.4 final\n",
       "--------------------------  ---------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "path = \"C:\\\\Users\\jmatney\\Documents\\GitHub\\IndianaRisk\"\n",
    "os.chdir(path)\n",
    "# data\n",
    "IN_df = pd.read_excel(\"data\\model_data\\IN_Risk_Model.xlsx\")\n",
    "IN_mod = IN_df.drop('subwatershed', 1)\n",
    "\n",
    "predictors = list(IN_mod.loc[:, IN_mod.columns != \"claims_total_building_insurance_coverage_avg\"].columns)\n",
    "response = \"claims_total_building_insurance_coverage_avg\"\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "IN_norm = scaler.fit_transform(IN_mod)\n",
    "IN_norm = pd.DataFrame(IN_norm, columns=IN_mod.columns)\n",
    "hf = h2o.H2OFrame(IN_norm)\n",
    "train, test = hf.split_frame(ratios=[.8])\n",
    "\n",
    "# # Import a sample binary outcome train/test set into H2O\n",
    "# train = h2o.import_file(\"https://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv\")\n",
    "# test = h2o.import_file(\"https://s3.amazonaws.com/erin-data/higgs/higgs_test_5k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify predictors and response\n",
    "x = predictors\n",
    "y = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For binary classification, response should be a factor\n",
    "# train[y] = train[y].asfactor()\n",
    "# test[y] = test[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of CV folds (to generate level-one data for stacking)\n",
    "nfolds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# There are a few ways to assemble a list of models to stack together:\n",
    "# 1. Train individual models and put them in a list\n",
    "# 2. Train a grid of models\n",
    "# 3. Train several grids of models\n",
    "# Note: All base models must have the same cross-validation folds and\n",
    "# the cross-validated predicted values must be kept.\n",
    "\n",
    "\n",
    "# 1. Generate a 2-model ensemble (GBM + RF)\n",
    "\n",
    "# Train and cross-validate a GBM\n",
    "my_gbm = H2OGradientBoostingEstimator(distribution=\"gaussian\",\n",
    "                                      ntrees=10,\n",
    "                                      max_depth=3,\n",
    "                                      min_rows=2,\n",
    "                                      learn_rate=0.2,\n",
    "                                      nfolds=nfolds,\n",
    "                                      fold_assignment=\"Modulo\",\n",
    "                                      keep_cross_validation_predictions=True,\n",
    "                                      seed=1)\n",
    "my_gbm.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Train and cross-validate a RF\n",
    "my_rf = H2ORandomForestEstimator(ntrees=50,\n",
    "                                 nfolds=nfolds,\n",
    "                                 fold_assignment=\"Modulo\",\n",
    "                                 keep_cross_validation_predictions=True,\n",
    "                                 seed=1)\n",
    "my_rf.train(x=x, y=y, training_frame=train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble Model Build progress: |███████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Train a stacked ensemble using the GBM and GLM above\n",
    "ensemble = H2OStackedEnsembleEstimator(model_id=\"my_ensemble_binomial\",\n",
    "                                       base_models=[my_gbm, my_rf])\n",
    "ensemble.train(x=x, y=y, training_frame=train)\n",
    "\n",
    "# Eval ensemble performance on the test data\n",
    "perf_stack_test = ensemble.model_performance(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Base-learner Test RMSE:  0.0816973251268041\n",
      "Ensemble Test RMSE:  0.07909706987951522\n",
      "stackedensemble prediction progress: |████████████████████████████████████| 100%\n",
      "gbm Grid Build progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Compare to base learner performance on the test set\n",
    "perf_gbm_test = my_gbm.model_performance(test)\n",
    "perf_rf_test = my_rf.model_performance(test)\n",
    "baselearner_best_rmse_test = max(perf_gbm_test.rmse(), perf_rf_test.rmse())\n",
    "stack_rmse_test = perf_stack_test.rmse()\n",
    "print(\"Best Base-learner Test RMSE:  {0}\".format(baselearner_best_rmse_test))\n",
    "print(\"Ensemble Test RMSE:  {0}\".format(stack_rmse_test))\n",
    "\n",
    "# Generate predictions on a test set (if neccessary)\n",
    "pred = ensemble.predict(test)\n",
    "\n",
    "\n",
    "# 2. Generate a random grid of models and stack them together\n",
    "\n",
    "# Specify GBM hyperparameters for the grid\n",
    "hyper_params = {\"learn_rate\": [0.01, 0.03],\n",
    "                \"max_depth\": [3, 4, 5, 6, 9],\n",
    "                \"sample_rate\": [0.7, 0.8, 0.9, 1.0],\n",
    "                \"col_sample_rate\": [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}\n",
    "search_criteria = {\"strategy\": \"RandomDiscrete\", \"max_models\": 3, \"seed\": 1}\n",
    "\n",
    "# Train the grid\n",
    "grid = H2OGridSearch(model=H2OGradientBoostingEstimator(ntrees=10,\n",
    "                                                        seed=1,\n",
    "                                                        nfolds=nfolds,\n",
    "                                                        fold_assignment=\"Modulo\",\n",
    "                                                        keep_cross_validation_predictions=True),\n",
    "                     hyper_params=hyper_params,\n",
    "                     search_criteria=search_criteria,\n",
    "                     grid_id=\"gbm_grid_binomial\")\n",
    "grid.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble Model Build progress: |███████████████████████████████████| 100%\n",
      "Best Base-learner Test RMSE:  0.0915179695188364\n",
      "Ensemble Test RMSE:  0.08237816341351313\n",
      "stackedensemble prediction progress: |████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Train a stacked ensemble using the GBM grid\n",
    "ensemble = H2OStackedEnsembleEstimator(model_id=\"my_ensemble_gbm_grid_binomial\",\n",
    "                                       base_models=grid.model_ids)\n",
    "ensemble.train(x=x, y=y, training_frame=train)\n",
    "\n",
    "# Eval ensemble performance on the test data\n",
    "perf_stack_test = ensemble.model_performance(test)\n",
    "\n",
    "# Compare to base learner performance on the test set\n",
    "baselearner_best_rmse_test = max([h2o.get_model(model).model_performance(test_data=test).rmse() for model in grid.model_ids])\n",
    "stack_rmse_test = perf_stack_test.rmse()\n",
    "print(\"Best Base-learner Test RMSE:  {0}\".format(baselearner_best_rmse_test))\n",
    "print(\"Ensemble Test RMSE:  {0}\".format(stack_rmse_test))\n",
    "\n",
    "# Generate predictions on a test set (if neccessary)\n",
    "pred = ensemble.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df=pd.DataFrame(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_norm_pred = IN_norm.drop(response,1)\n",
    "IN_norm_pred\n",
    "# IN_norm_pred = pd.concat([IN_norm_pred, pred], axis=1)\n",
    "ensemble_pred = scaler.inverse_transform(IN_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_norm_pred[response] = pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_norm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.299470</td>\n",
       "      <td>1.010000e+02</td>\n",
       "      <td>11.031308</td>\n",
       "      <td>0.307262</td>\n",
       "      <td>0.412036</td>\n",
       "      <td>9.386736</td>\n",
       "      <td>3.610590e-03</td>\n",
       "      <td>0.050787</td>\n",
       "      <td>0.697929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>193.107921</td>\n",
       "      <td>58111.000000</td>\n",
       "      <td>1673.0</td>\n",
       "      <td>41.366667</td>\n",
       "      <td>884.262553</td>\n",
       "      <td>503.506692</td>\n",
       "      <td>0.146502</td>\n",
       "      <td>6789.381348</td>\n",
       "      <td>3212.713978</td>\n",
       "      <td>1180.826665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.485784</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>4.080327</td>\n",
       "      <td>0.718304</td>\n",
       "      <td>0.283812</td>\n",
       "      <td>1.484138</td>\n",
       "      <td>4.839883e-03</td>\n",
       "      <td>0.014050</td>\n",
       "      <td>4.034926</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>104.643085</td>\n",
       "      <td>56771.333333</td>\n",
       "      <td>-431.0</td>\n",
       "      <td>41.466667</td>\n",
       "      <td>1261.467019</td>\n",
       "      <td>535.669076</td>\n",
       "      <td>1.180721</td>\n",
       "      <td>6862.660156</td>\n",
       "      <td>25613.870480</td>\n",
       "      <td>2713.363580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.322675</td>\n",
       "      <td>2.600000e+01</td>\n",
       "      <td>2.030253</td>\n",
       "      <td>0.815297</td>\n",
       "      <td>0.647139</td>\n",
       "      <td>1.778003</td>\n",
       "      <td>2.980456e-03</td>\n",
       "      <td>0.017181</td>\n",
       "      <td>2.977041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>321.678527</td>\n",
       "      <td>48506.750000</td>\n",
       "      <td>-243.0</td>\n",
       "      <td>41.675000</td>\n",
       "      <td>584.613292</td>\n",
       "      <td>297.702490</td>\n",
       "      <td>1.084871</td>\n",
       "      <td>6175.916504</td>\n",
       "      <td>27111.136390</td>\n",
       "      <td>28374.903350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.326203</td>\n",
       "      <td>3.710738e-09</td>\n",
       "      <td>2.053226</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.308209</td>\n",
       "      <td>1.027938</td>\n",
       "      <td>4.436303e-13</td>\n",
       "      <td>0.009651</td>\n",
       "      <td>4.357636</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>366.175097</td>\n",
       "      <td>61766.200000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1087.881755</td>\n",
       "      <td>964.682414</td>\n",
       "      <td>4.389772</td>\n",
       "      <td>5982.229004</td>\n",
       "      <td>33976.722030</td>\n",
       "      <td>43.018237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.379072</td>\n",
       "      <td>7.600000e+01</td>\n",
       "      <td>10.546125</td>\n",
       "      <td>0.172761</td>\n",
       "      <td>0.501159</td>\n",
       "      <td>3.978998</td>\n",
       "      <td>4.231477e-03</td>\n",
       "      <td>0.068939</td>\n",
       "      <td>18.411886</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>256.032460</td>\n",
       "      <td>55698.400000</td>\n",
       "      <td>-833.0</td>\n",
       "      <td>40.660000</td>\n",
       "      <td>555.426454</td>\n",
       "      <td>409.885301</td>\n",
       "      <td>1.661841</td>\n",
       "      <td>5676.336426</td>\n",
       "      <td>63568.611420</td>\n",
       "      <td>9695.319736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>0.240000</td>\n",
       "      <td>3.710000e+01</td>\n",
       "      <td>3.470000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>3.830000</td>\n",
       "      <td>82.0</td>\n",
       "      <td>...</td>\n",
       "      <td>359.640000</td>\n",
       "      <td>51922.500000</td>\n",
       "      <td>-261.0</td>\n",
       "      <td>42.930000</td>\n",
       "      <td>912.910000</td>\n",
       "      <td>796.990000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>6789.380000</td>\n",
       "      <td>37197.085120</td>\n",
       "      <td>8582.128831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>0.390000</td>\n",
       "      <td>1.949000e+01</td>\n",
       "      <td>1.160000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>173.150000</td>\n",
       "      <td>53627.670000</td>\n",
       "      <td>-684.0</td>\n",
       "      <td>41.600000</td>\n",
       "      <td>865.100000</td>\n",
       "      <td>516.570000</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>6639.860000</td>\n",
       "      <td>17181.581280</td>\n",
       "      <td>23632.585480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>0.380000</td>\n",
       "      <td>1.949000e+01</td>\n",
       "      <td>1.160000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>1.930000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>34.480000</td>\n",
       "      <td>122.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95.140000</td>\n",
       "      <td>52547.500000</td>\n",
       "      <td>57.0</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>450.170000</td>\n",
       "      <td>253.230000</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>6639.860000</td>\n",
       "      <td>27942.486560</td>\n",
       "      <td>2902.555628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>0.280000</td>\n",
       "      <td>5.801000e+01</td>\n",
       "      <td>3.540000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>4.970000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>12.670000</td>\n",
       "      <td>250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>602.750000</td>\n",
       "      <td>74185.500000</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>40.160000</td>\n",
       "      <td>1093.700000</td>\n",
       "      <td>788.000000</td>\n",
       "      <td>9.340000</td>\n",
       "      <td>7600.010000</td>\n",
       "      <td>21593.433150</td>\n",
       "      <td>18142.836830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>0.380000</td>\n",
       "      <td>2.760000e+01</td>\n",
       "      <td>1.610000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49.030000</td>\n",
       "      <td>49884.000000</td>\n",
       "      <td>-148.0</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>588.110000</td>\n",
       "      <td>396.280000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>6860.070000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>763 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0             1          2         3         4         5   \\\n",
       "0    0.299470  1.010000e+02  11.031308  0.307262  0.412036  9.386736   \n",
       "1    0.485784  5.000000e+01   4.080327  0.718304  0.283812  1.484138   \n",
       "2    0.322675  2.600000e+01   2.030253  0.815297  0.647139  1.778003   \n",
       "3    0.326203  3.710738e-09   2.053226  0.000588  0.308209  1.027938   \n",
       "4    0.379072  7.600000e+01  10.546125  0.172761  0.501159  3.978998   \n",
       "..        ...           ...        ...       ...       ...       ...   \n",
       "758  0.240000  3.710000e+01   3.470000  0.440000  0.250000  3.500000   \n",
       "759  0.390000  1.949000e+01   1.160000  0.790000  0.490000  2.020000   \n",
       "760  0.380000  1.949000e+01   1.160000  0.580000  0.820000  1.930000   \n",
       "761  0.280000  5.801000e+01   3.540000  0.460000  0.350000  4.970000   \n",
       "762  0.380000  2.760000e+01   1.610000  0.930000  0.600000  1.470000   \n",
       "\n",
       "               6         7          8      9   ...          16            17  \\\n",
       "0    3.610590e-03  0.050787   0.697929    0.0  ...  193.107921  58111.000000   \n",
       "1    4.839883e-03  0.014050   4.034926    1.0  ...  104.643085  56771.333333   \n",
       "2    2.980456e-03  0.017181   2.977041    0.0  ...  321.678527  48506.750000   \n",
       "3    4.436303e-13  0.009651   4.357636   25.0  ...  366.175097  61766.200000   \n",
       "4    4.231477e-03  0.068939  18.411886   10.0  ...  256.032460  55698.400000   \n",
       "..            ...       ...        ...    ...  ...         ...           ...   \n",
       "758  0.000000e+00  0.010000   3.830000   82.0  ...  359.640000  51922.500000   \n",
       "759  0.000000e+00  0.010000   0.000000    0.0  ...  173.150000  53627.670000   \n",
       "760  0.000000e+00  0.020000  34.480000  122.0  ...   95.140000  52547.500000   \n",
       "761  0.000000e+00  0.020000  12.670000  250.0  ...  602.750000  74185.500000   \n",
       "762  0.000000e+00  0.020000   0.000000    0.0  ...   49.030000  49884.000000   \n",
       "\n",
       "         18         19           20          21        22           23  \\\n",
       "0    1673.0  41.366667   884.262553  503.506692  0.146502  6789.381348   \n",
       "1    -431.0  41.466667  1261.467019  535.669076  1.180721  6862.660156   \n",
       "2    -243.0  41.675000   584.613292  297.702490  1.084871  6175.916504   \n",
       "3      38.0  42.000000  1087.881755  964.682414  4.389772  5982.229004   \n",
       "4    -833.0  40.660000   555.426454  409.885301  1.661841  5676.336426   \n",
       "..      ...        ...          ...         ...       ...          ...   \n",
       "758  -261.0  42.930000   912.910000  796.990000  0.150000  6789.380000   \n",
       "759  -684.0  41.600000   865.100000  516.570000  1.390000  6639.860000   \n",
       "760    57.0  38.500000   450.170000  253.230000  1.390000  6639.860000   \n",
       "761  2295.0  40.160000  1093.700000  788.000000  9.340000  7600.010000   \n",
       "762  -148.0  39.500000   588.110000  396.280000  0.980000  6860.070000   \n",
       "\n",
       "               24            25  \n",
       "0     3212.713978   1180.826665  \n",
       "1    25613.870480   2713.363580  \n",
       "2    27111.136390  28374.903350  \n",
       "3    33976.722030     43.018237  \n",
       "4    63568.611420   9695.319736  \n",
       "..            ...           ...  \n",
       "758  37197.085120   8582.128831  \n",
       "759  17181.581280  23632.585480  \n",
       "760  27942.486560   2902.555628  \n",
       "761  21593.433150  18142.836830  \n",
       "762      0.000000      0.000000  \n",
       "\n",
       "[763 rows x 26 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ensemble_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
